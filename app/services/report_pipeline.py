"""
æŠ¥å‘Šç”Ÿæˆç®¡çº¿

ä¸²è”æ‰€æœ‰æ¨¡å—ï¼Œç”Ÿæˆå®Œæ•´çš„é‚®ä»¶æŠ¥å‘Š
"""
import re
from datetime import date, timedelta
from typing import Optional, Dict, Any

from google.oauth2.credentials import Credentials

from app.core.logging import get_logger
from app.integrations.gmail.auth import SkillGmailAuth, AuthError
from app.integrations.gmail.fetch import SkillGmailFetch
from app.integrations.gmail.normalize import SkillEmailNormalize
from app.services.thread_merge import SkillThreadMerge
from app.services.importance import SkillImportanceHeuristics
from app.integrations.openai.prompts import SkillPromptCompose
from app.integrations.openai.summarize import SkillGptSummarize, GptError
from app.integrations.anthropic.summarize import SkillClaudeSummarize, ClaudeError
from app.core.config import config as app_config
from app.db.report_store import SkillReportStore, ReportData

logger = get_logger(__name__)


class ReportPipelineError(Exception):
    """æŠ¥å‘Šç”Ÿæˆç®¡çº¿é”™è¯¯"""
    pass


class ReportPipeline:
    """
    æŠ¥å‘Šç”Ÿæˆç®¡çº¿

    å®Œæ•´çš„æŠ¥å‘Šç”Ÿæˆæµç¨‹
    """

    @staticmethod
    def generate_report_for_date(
        report_date: date,
        credentials: Optional[Credentials] = None,
        last_n_hours: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        ç”ŸæˆæŒ‡å®šæ—¥æœŸçš„é‚®ä»¶æŠ¥å‘Š

        Args:
            report_date: æŠ¥å‘Šæ—¥æœŸ
            credentials: Google å‡­æ®ï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨åŠ è½½
            last_n_hours: æ‹‰å–æœ€è¿‘ N å°æ—¶çš„é‚®ä»¶ï¼Œå¦‚æœæŒ‡å®šåˆ™å¿½ç•¥ date èŒƒå›´

        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šå­—å…¸ï¼ŒåŒ…å« report_id å’Œ summary

        Raises:
            AuthError: è®¤è¯å¤±è´¥
            ReportPipelineError: ç®¡çº¿æ‰§è¡Œå¤±è´¥
        """
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹ç”ŸæˆæŠ¥å‘Š: {report_date}")
        logger.info("=" * 60)

        try:
            # Step 1: åŠ è½½å‡­æ®
            logger.info("æ­¥éª¤ 1/7: åŠ è½½ Gmail å‡­æ®")
            if credentials is None:
                credentials = SkillGmailAuth.load_credentials()
                if credentials is None:
                    raise AuthError("æœªæ‰¾åˆ°æœ‰æ•ˆå‡­æ®ï¼Œè¯·å…ˆè¿›è¡Œæˆæƒ", needs_reauth=True)
            logger.info("âœ“ å‡­æ®åŠ è½½æˆåŠŸ")

            # Step 2: æ‹‰å–é‚®ä»¶
            logger.info("æ­¥éª¤ 2/7: æ‹‰å–é‚®ä»¶")
            if last_n_hours:
                # æœ€è¿‘ N å°æ—¶
                messages = SkillGmailFetch.fetch_messages(
                    credentials=credentials,
                    last_n_hours=last_n_hours,
                    max_results=100
                )
                logger.info(f"âœ“ æ‹‰å–äº†æœ€è¿‘ {last_n_hours} å°æ—¶çš„ {len(messages)} å°é‚®ä»¶")
            else:
                # æŒ‡å®šæ—¥æœŸï¼ˆå½“å¤© 00:00 åˆ° 23:59ï¼‰
                messages = SkillGmailFetch.fetch_messages(
                    credentials=credentials,
                    date_from=report_date,
                    date_to=report_date,
                    max_results=100
                )
                logger.info(f"âœ“ æ‹‰å–äº† {len(messages)} å°é‚®ä»¶")

            # æ£€æŸ¥æ˜¯å¦æœ‰é‚®ä»¶
            if not messages:
                logger.info("æ²¡æœ‰é‚®ä»¶ï¼Œç”Ÿæˆç©ºæŠ¥å‘Š")
                return ReportPipeline._generate_empty_report(report_date)

            # Step 3: å½’ä¸€åŒ–é‚®ä»¶
            logger.info("æ­¥éª¤ 3/7: å½’ä¸€åŒ–é‚®ä»¶")
            normalized_emails = []
            for msg in messages:
                normalized = SkillEmailNormalize.normalize(msg)
                normalized_emails.append(normalized)
            logger.info(f"âœ“ å½’ä¸€åŒ–äº† {len(normalized_emails)} å°é‚®ä»¶")

            # Step 4: åˆå¹¶çº¿ç¨‹
            logger.info("æ­¥éª¤ 4/7: åˆå¹¶çº¿ç¨‹")
            threads = SkillThreadMerge.merge_threads(normalized_emails)
            logger.info(f"âœ“ åˆå¹¶ä¸º {len(threads)} ä¸ªçº¿ç¨‹")

            # Step 5: é‡è¦æ€§è¯„åˆ†
            logger.info("æ­¥éª¤ 5/7: é‡è¦æ€§è¯„åˆ†")
            scorer = SkillImportanceHeuristics()
            scored_threads = scorer.prioritize_threads(threads)
            logger.info(f"âœ“ å®Œæˆè¯„åˆ†ï¼Œæœ€é«˜åˆ†: {scored_threads[0][1]:.1f}" if scored_threads else "âœ“ å®Œæˆè¯„åˆ†")

            # Step 6: ç”Ÿæˆ Prompt å¹¶è°ƒç”¨ AI
            ai_provider = app_config.AI_PROVIDER
            logger.info(f"æ­¥éª¤ 6/7: è°ƒç”¨ {ai_provider.upper()} ç”ŸæˆæŠ¥å‘Š")
            system_prompt, user_prompt = SkillPromptCompose.compose(
                scored_threads,
                report_date
            )

            try:
                # æ ¹æ®é…ç½®é€‰æ‹© AI æä¾›å•†
                if ai_provider == "claude":
                    ai_client = SkillClaudeSummarize()
                    ai_response = ai_client.summarize(system_prompt, user_prompt)
                else:  # openai
                    ai_client = SkillGptSummarize()
                    ai_response = ai_client.summarize(system_prompt, user_prompt)

                # æ ¹æ®æ ¼å¼è§£æå“åº”
                if ai_response.get('format') == 'markdown':
                    summary = ReportPipeline._parse_markdown_report(ai_response['content'])
                else:
                    summary = ai_response  # æ—§ JSON æ ¼å¼

                # éªŒè¯æŠ¥å‘Šç»“æ„
                if not ai_client.validate_report(ai_response):
                    logger.warning("AI è¿”å›çš„æŠ¥å‘Šç»“æ„ä¸å®Œæ•´ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
                    summary = ReportPipeline._fix_report_structure(summary)

                logger.info(f"âœ“ {ai_provider.upper()} æŠ¥å‘Šç”ŸæˆæˆåŠŸ")

            except (GptError, ClaudeError) as e:
                logger.error(f"AI è°ƒç”¨å¤±è´¥: {e}")
                # ç”Ÿæˆé™çº§æŠ¥å‘Šï¼ˆä¸ä½¿ç”¨ AIï¼‰
                summary = ReportPipeline._generate_fallback_summary(scored_threads)
                logger.info("âœ“ ä½¿ç”¨é™çº§æŠ¥å‘Šï¼ˆæœªè°ƒç”¨ AIï¼‰")

            # Step 7: ä¿å­˜æŠ¥å‘Š
            logger.info("æ­¥éª¤ 7/7: ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“")

            # æ„å»ºé‚®ä»¶å¼•ç”¨
            email_refs = []
            for thread, score in scored_threads[:20]:  # æœ€å¤šä¿å­˜ 20 ä¸ªçº¿ç¨‹çš„å¼•ç”¨
                for msg in thread.messages:
                    email_refs.append({
                        'message_id': msg.message_id,
                        'thread_id': msg.thread_id,
                        'subject': msg.subject,
                        'from_addr': msg.from_addr,
                        'to_addr': msg.to_addr,
                        'date': msg.date,
                        'snippet': msg.snippet,
                        'gmail_url': f"https://mail.google.com/mail/u/0/#inbox/{msg.message_id}"
                    })

            # åˆ›å»ºæŠ¥å‘Šæ•°æ®
            report_data = ReportData(
                date=report_date,
                summary=summary,
                email_refs=email_refs
            )

            # ä¿å­˜
            report_id = SkillReportStore.save_report(report_data)
            logger.info(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜ï¼ŒID: {report_id}")

            logger.info("=" * 60)
            logger.info(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼æŠ¥å‘Š ID: {report_id}")
            logger.info("=" * 60)

            return {
                'report_id': report_id,
                'date': report_date.isoformat(),
                'summary': summary,
                'email_count': len(messages),
                'thread_count': len(threads),
                'reference_count': len(email_refs)
            }

        except AuthError:
            # é‡æ–°æŠ›å‡ºè®¤è¯é”™è¯¯
            raise

        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
            raise ReportPipelineError(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}") from e

    @staticmethod
    def _generate_empty_report(report_date: date) -> Dict[str, Any]:
        """
        ç”Ÿæˆç©ºæŠ¥å‘Š

        Args:
            report_date: æŠ¥å‘Šæ—¥æœŸ

        Returns:
            æŠ¥å‘Šå­—å…¸
        """
        summary = {
            'highlights': ['ä»Šæ—¥æ— æ–°é‚®ä»¶'],
            'todos': [],
            'categories': {
                'action_required': [],
                'important': [],
                'billing': [],
                'social': [],
                'other': []
            }
        }

        report_data = ReportData(
            date=report_date,
            summary=summary,
            email_refs=[]
        )

        report_id = SkillReportStore.save_report(report_data)
        logger.info(f"âœ“ ç©ºæŠ¥å‘Šå·²ä¿å­˜ï¼ŒID: {report_id}")

        return {
            'report_id': report_id,
            'date': report_date.isoformat(),
            'summary': summary,
            'email_count': 0,
            'thread_count': 0,
            'reference_count': 0
        }

    @staticmethod
    def _generate_fallback_summary(scored_threads) -> Dict[str, Any]:
        """
        ç”Ÿæˆé™çº§æ‘˜è¦ï¼ˆä¸ä½¿ç”¨ AIï¼‰

        Args:
            scored_threads: è¯„åˆ†åçš„çº¿ç¨‹åˆ—è¡¨

        Returns:
            Markdown æ ¼å¼çš„ç®€å•æŠ¥å‘Š
        """
        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        high_priority = []
        medium_priority = []
        low_priority = []

        total_emails = 0
        for thread, score in scored_threads:
            total_emails += thread.total_messages
            if score >= 15:
                high_priority.append((thread, score))
            elif score >= 5:
                medium_priority.append((thread, score))
            else:
                low_priority.append((thread, score))

        # ç”Ÿæˆ Markdown æŠ¥å‘Š
        report_parts = [
            "## é‚®ä»¶æ‘˜è¦ï¼ˆç®€åŒ–ç‰ˆï¼‰",
            "*æ­¤æŠ¥å‘Šæœªä½¿ç”¨ AI ç”Ÿæˆ*",
            ""
        ]

        # é«˜ä¼˜å…ˆçº§é‚®ä»¶
        if high_priority:
            report_parts.append("### é«˜ä¼˜å…ˆçº§é‚®ä»¶")
            report_parts.append("")
            for thread, score in high_priority[:10]:
                sender_name = "æœªçŸ¥å‘ä»¶äºº"
                if thread.messages:
                    first_msg = thread.messages[0]
                    sender_name = first_msg.sender_name or first_msg.from_addr or "æœªçŸ¥"

                report_parts.append(f"**{thread.subject}**")
                report_parts.append(f"- å‘ä»¶äºº: {sender_name}")
                report_parts.append(f"- é‡è¦æ€§: {score:.1f}")
                report_parts.append(f"- é‚®ä»¶æ•°: {thread.total_messages}")

                if thread.has_attachments:
                    report_parts.append("- ğŸ“ åŒ…å«é™„ä»¶")

                # æ‘˜è¦ç‰‡æ®µ
                if thread.messages and thread.messages[0].snippet:
                    snippet = thread.messages[0].snippet[:100]
                    report_parts.append(f"- å†…å®¹: {snippet}...")

                report_parts.append("")

        # ä¸­ç­‰ä¼˜å…ˆçº§
        if medium_priority:
            report_parts.append("### ä¸­ç­‰ä¼˜å…ˆçº§é‚®ä»¶")
            report_parts.append("")
            for thread, score in medium_priority[:10]:
                sender_name = "æœªçŸ¥"
                if thread.messages:
                    first_msg = thread.messages[0]
                    sender_name = first_msg.sender_name or first_msg.from_addr or "æœªçŸ¥"

                report_parts.append(f"- **{thread.subject}** (å‘ä»¶äºº: {sender_name}, é‡è¦æ€§: {score:.1f})")

            report_parts.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        report_parts.append("### ç»Ÿè®¡ä¿¡æ¯")
        report_parts.append("")
        report_parts.append(f"- æ€»çº¿ç¨‹æ•°: {len(scored_threads)}")
        report_parts.append(f"- æ€»é‚®ä»¶æ•°: {total_emails}")
        report_parts.append(f"- é«˜ä¼˜å…ˆçº§: {len(high_priority)}")
        report_parts.append(f"- ä¸­ç­‰ä¼˜å…ˆçº§: {len(medium_priority)}")
        report_parts.append(f"- ä½ä¼˜å…ˆçº§: {len(low_priority)}")

        markdown_content = "\n".join(report_parts)

        return {
            'format': 'markdown',
            'full_content': markdown_content,
            'highlights': [f"å…±æ”¶åˆ° {len(scored_threads)} ä¸ªé‚®ä»¶çº¿ç¨‹"],
            'todos': ["æŸ¥çœ‹é«˜ä¼˜å…ˆçº§é‚®ä»¶"] if high_priority else ["æŸ¥çœ‹ä»Šæ—¥é‚®ä»¶"],
            'sections': {}
        }

    @staticmethod
    def _parse_markdown_report(markdown_content: str) -> Dict[str, Any]:
        """
        ä» Markdown æŠ¥å‘Šä¸­æå–ç»“æ„åŒ–æ•°æ®

        æå–ï¼š
        - highlightsï¼ˆä»"ä»Šæ—¥é‡ç‚¹"æˆ–"é‡ç‚¹"ç« èŠ‚ï¼‰
        - todosï¼ˆä»"å¾…åŠ"æˆ–"ä»»åŠ¡"ç« èŠ‚ï¼‰
        - å®Œæ•´ markdownï¼ˆç”¨äºæ˜¾ç¤ºï¼‰

        è¿”å›ä¸æ•°æ®åº“å­˜å‚¨å…¼å®¹çš„ç»“æ„

        Args:
            markdown_content: Markdown æ ¼å¼çš„æŠ¥å‘Šå†…å®¹

        Returns:
            åŒ…å«ç»“æ„åŒ–æ•°æ®çš„å­—å…¸
        """
        result = {
            'format': 'markdown',
            'full_content': markdown_content,
            'highlights': [],
            'todos': [],
            'sections': {}
        }

        try:
            # ä½¿ç”¨æ­£åˆ™æå–ç« èŠ‚ï¼š## ç« èŠ‚å\nå†…å®¹...
            sections = re.split(r'\n##\s+', markdown_content)

            for section in sections:
                if not section.strip():
                    continue

                # æå–ç« èŠ‚æ ‡é¢˜å’Œå†…å®¹
                lines = section.split('\n', 1)
                if len(lines) < 2:
                    continue

                title = lines[0].strip()
                content = lines[1].strip()

                # å­˜å‚¨ç« èŠ‚
                result['sections'][title] = content

                # è¯†åˆ«"é‡ç‚¹"ã€"å¾…åŠ"ç­‰å…³é”®è¯
                title_lower = title.lower()

                if any(keyword in title_lower for keyword in ['é‡ç‚¹', 'highlight', 'å‘ç°']):
                    # æå–åˆ—è¡¨é¡¹
                    items = re.findall(r'^[-*]\s+(.+)$', content, re.MULTILINE)
                    result['highlights'].extend(items[:7])

                elif any(keyword in title_lower for keyword in ['å¾…åŠ', 'todo', 'ä»»åŠ¡', 'task']):
                    # æå–åˆ—è¡¨é¡¹
                    items = re.findall(r'^[-*\[\]]\s+(.+)$', content, re.MULTILINE)
                    # æ¸…ç†å¤é€‰æ¡†æ ‡è®°
                    cleaned_items = [re.sub(r'^\[.\]\s*', '', item) for item in items]
                    result['todos'].extend(cleaned_items)

            # å¦‚æœæ²¡æœ‰æå–åˆ° highlightsï¼Œå°è¯•ä»ç¬¬ä¸€æ®µæå–
            if not result['highlights'] and markdown_content:
                first_lines = markdown_content.split('\n\n')[0]
                if first_lines:
                    result['highlights'].append(first_lines[:200])

        except Exception as e:
            logger.warning(f"è§£æ Markdown æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            # å¤±è´¥æ—¶è‡³å°‘ä¿ç•™å®Œæ•´å†…å®¹
            result['highlights'] = ['æŠ¥å‘Šå·²ç”Ÿæˆï¼Œè¯·æŸ¥çœ‹å®Œæ•´å†…å®¹']

        return result

    @staticmethod
    def _fix_report_structure(summary: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¿®å¤ä¸å®Œæ•´çš„æŠ¥å‘Šç»“æ„

        Args:
            summary: åŸå§‹æŠ¥å‘Š

        Returns:
            ä¿®å¤åçš„æŠ¥å‘Š
        """
        # Markdown æ ¼å¼
        if summary.get('format') == 'markdown':
            if 'full_content' not in summary:
                summary['full_content'] = 'æŠ¥å‘Šç”Ÿæˆä¸­å‡ºç°å¼‚å¸¸'
            if 'highlights' not in summary:
                summary['highlights'] = ['æŠ¥å‘Šç”Ÿæˆä¸­å‡ºç°å¼‚å¸¸']
            if 'todos' not in summary:
                summary['todos'] = []
            return summary

        # JSON æ ¼å¼ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        if 'highlights' not in summary:
            summary['highlights'] = ['æŠ¥å‘Šç”Ÿæˆä¸­å‡ºç°å¼‚å¸¸']

        if 'todos' not in summary:
            summary['todos'] = []

        if 'categories' not in summary:
            summary['categories'] = {
                'action_required': [],
                'important': [],
                'billing': [],
                'social': [],
                'other': []
            }

        return summary
